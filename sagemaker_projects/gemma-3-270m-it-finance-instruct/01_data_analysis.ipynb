{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset Analysis: Finance-Instruct-500k\n",
        "\n",
        "This notebook loads and explores the [Josephgflowers/Finance-Instruct-500k](https://huggingface.co/datasets/Josephgflowers/Finance-Instruct-500k) dataset to prepare training/validation subsets for fine-tuning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"Josephgflowers/Finance-Instruct-500k\")\n",
        "dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to DataFrame for easier exploration\n",
        "df = dataset[\"train\"].to_pandas()\n",
        "print(f\"Shape: {df.shape}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Column info\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample a few examples\n",
        "for i, row in df.sample(3).iterrows():\n",
        "    print(\"=\" * 80)\n",
        "    for col in df.columns:\n",
        "        val = row[col]\n",
        "        if isinstance(val, str) and len(val) > 500:\n",
        "            val = val[:500] + \"...\"\n",
        "        print(f\"\\n{col.upper()}:\\n{val}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Identify Use Cases\n",
        "\n",
        "The dataset supports 8 use cases (QA, Reasoning, Conversational AI, NER, Sentiment, Topic Classification, LLM Training, RAG). We'll use heuristics to classify entries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_task(row):\n",
        "    \"\"\"Heuristic classification based on prompt content\"\"\"\n",
        "    system = str(row.get('system', '')).lower()\n",
        "    user = str(row.get('user', '')).lower()\n",
        "    assistant = str(row.get('assistant', '')).lower()\n",
        "    combined = system + ' ' + user\n",
        "    \n",
        "    # Topic Classification patterns\n",
        "    if any(x in combined for x in ['classify', 'categorize', 'topic', 'category']):\n",
        "        if any(x in combined for x in ['topic', 'category', 'categories']):\n",
        "            return 'topic_classification'\n",
        "    \n",
        "    # Sentiment Analysis patterns\n",
        "    if any(x in combined for x in ['sentiment', 'bullish', 'bearish', 'positive', 'negative']):\n",
        "        return 'sentiment_analysis'\n",
        "    \n",
        "    # NER patterns\n",
        "    if any(x in combined for x in ['entity', 'entities', 'ner', 'extract', 'xbrl', 'tag']):\n",
        "        return 'ner'\n",
        "    \n",
        "    # QA patterns\n",
        "    if any(x in combined for x in ['question', 'answer', 'what is', 'explain', 'define']):\n",
        "        return 'qa'\n",
        "    \n",
        "    # Reasoning patterns\n",
        "    if any(x in combined for x in ['calculate', 'compute', 'analyze', 'reasoning', 'portfolio']):\n",
        "        return 'reasoning'\n",
        "    \n",
        "    # RAG patterns (external context prepended)\n",
        "    if len(user) > 1000 and 'context' in combined:\n",
        "        return 'rag'\n",
        "    \n",
        "    return 'other'\n",
        "\n",
        "df['task_type'] = df.apply(classify_task, axis=1)\n",
        "df['task_type'].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sentiment Analysis Subset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter for sentiment analysis examples\n",
        "sentiment_df = df[df['task_type'] == 'sentiment_analysis']\n",
        "print(f\"Sentiment analysis samples: {len(sentiment_df)}\")\n",
        "sentiment_df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examine sentiment analysis examples\n",
        "for i, row in sentiment_df.sample(min(5, len(sentiment_df))).iterrows():\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"SYSTEM:\\n{row['system'][:300] if row['system'] else 'N/A'}\")\n",
        "    print(f\"\\nUSER:\\n{row['user'][:300]}\")\n",
        "    print(f\"\\nASSISTANT:\\n{row['assistant'][:200]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group by distinct assistant answers\n",
        "sentiment_df['assistant'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create cleansed dataset with only valid sentiment labels\n",
        "valid_labels = ['neutral', 'positive', 'negative', 'bullish']\n",
        "sentiment_clean_df = sentiment_df[sentiment_df['assistant'].isin(valid_labels)].copy()\n",
        "\n",
        "print(f\"Original: {len(sentiment_df)} rows\")\n",
        "print(f\"Cleansed: {len(sentiment_clean_df)} rows\")\n",
        "print(f\"\\nLabel distribution:\")\n",
        "sentiment_clean_df['assistant'].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Balanced Training Dataset (6000 samples)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add word count columns\n",
        "sentiment_clean_df['user_words'] = sentiment_clean_df['user'].str.split().str.len()\n",
        "sentiment_clean_df['assistant_words'] = sentiment_clean_df['assistant'].str.split().str.len()\n",
        "sentiment_clean_df['total_words'] = sentiment_clean_df['user_words'] + sentiment_clean_df['assistant_words']\n",
        "\n",
        "# Filter by max word count (~400 words â‰ˆ 512 tokens)\n",
        "max_words = 400\n",
        "filtered_df = sentiment_clean_df[sentiment_clean_df['total_words'] <= max_words].copy()\n",
        "\n",
        "print(f\"After length filter: {len(filtered_df)} rows\")\n",
        "print(f\"Per label:\\n{filtered_df['assistant'].value_counts()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove near-duplicates for diversity (based on first 100 chars of user text)\n",
        "filtered_df['user_key'] = filtered_df['user'].str[:100]\n",
        "deduped_df = filtered_df.drop_duplicates(subset=['user_key', 'assistant'])\n",
        "\n",
        "print(f\"After deduplication: {len(deduped_df)} rows\")\n",
        "print(f\"Per label:\\n{deduped_df['assistant'].value_counts()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Balanced sample: 1500 from each label (6000 total)\n",
        "final_samples = []\n",
        "for label in ['neutral', 'positive', 'negative', 'bullish']:\n",
        "    label_df = deduped_df[deduped_df['assistant'] == label]\n",
        "    n_sample = min(1500, len(label_df))\n",
        "    sampled = label_df.sample(n=n_sample, random_state=42)\n",
        "    final_samples.append(sampled)\n",
        "    print(f\"{label}: sampled {n_sample}\")\n",
        "\n",
        "final_df = pd.concat(final_samples, ignore_index=True)\n",
        "\n",
        "# Drop temp columns\n",
        "final_df = final_df.drop(columns=['user_key', 'task_type', 'user_words', 'assistant_words', 'total_words'])\n",
        "print(f\"\\nFinal dataset: {len(final_df)} rows\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final dataset stats\n",
        "final_df['user_words'] = final_df['user'].str.split().str.len()\n",
        "final_df['total_words'] = final_df['user_words'] + final_df['assistant'].str.split().str.len()\n",
        "\n",
        "print(\"=== Final Dataset Stats ===\")\n",
        "print(f\"Total rows: {len(final_df)}\")\n",
        "print(f\"\\nLabel distribution:\\n{final_df['assistant'].value_counts()}\")\n",
        "print(f\"\\nWord count stats:\")\n",
        "print(final_df['total_words'].describe())\n",
        "print(f\"\\nUser text word count stats:\")\n",
        "print(final_df['user_words'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview a few examples from each label\n",
        "for label in ['neutral', 'positive', 'negative', 'bullish']:\n",
        "    print(f\"\\n{'='*60}\\n{label.upper()} EXAMPLE:\\n{'='*60}\")\n",
        "    row = final_df[final_df['assistant'] == label].sample(1).iloc[0]\n",
        "    print(f\"USER ({len(row['user'].split())} words):\\n{row['user'][:400]}\")\n",
        "    print(f\"\\nASSISTANT: {row['assistant']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Training Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export to CSV (only core columns)\n",
        "output_path = \"sentiment_training_data.csv\"\n",
        "export_df = final_df[['system', 'user', 'assistant']].copy()\n",
        "export_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Exported {len(export_df)} rows to {output_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
